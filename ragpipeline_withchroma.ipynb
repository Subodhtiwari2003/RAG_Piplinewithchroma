{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3405b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs loaded: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "## Load The data \n",
    "URL = [\n",
    "    \"https://en.wikipedia.org/wiki/Titanic\",\n",
    "    \"https://www.investopedia.com/terms/s/stockmarket.asp\"\n",
    "]\n",
    "#load the data\n",
    "loader = WebBaseLoader(URL)\n",
    "docs = loader.load()\n",
    "print(\"Docs loaded:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8a107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256,chunk_overlap=50)\n",
    "chunking = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115e8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_30964\\3698268976.py:10: LangChainDeprecationWarning: The class `HuggingFaceInferenceAPIEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpointEmbeddings``.\n",
      "  embeddings = HuggingFaceInferenceAPIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# get your free access token from HuggingFace and paste it here\n",
    "HF_token = getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_token\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key = HF_token,model_name = \"BAAI/bge-base-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe8b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_30964\\1341209866.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\rag_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vectorstore created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_30964\\1341209866.py:13: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunking,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"my_collection\",\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(\"âœ… Vectorstore created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65472d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Document 1:\n",
      "Why Is the Stock Market So Important?\n",
      "\n",
      "ðŸ“Œ Document 2:\n",
      "How Stock Prices Are Determined\n",
      "\n",
      "ðŸ“Œ Document 3:\n",
      "Those in the stock market include institutional investors, such as pension funds, mutual funds, insurance companies, and hedge funds, that manage large amounts of money and often have a significant influence over the market since they are trading in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_30964\\2641241717.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs_rel = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3})\n",
    "\n",
    "query = \"What are the main factors that influence stock prices?\"\n",
    "docs_rel = retriever.get_relevant_documents(query)\n",
    "\n",
    "for i, doc in enumerate(docs_rel, 1):\n",
    "    print(f\"\\nðŸ“Œ Document {i}:\")\n",
    "    print(doc.page_content[:500])  # show first 500 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b41ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "<|system|>>\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in context\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e679eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "model = HuggingFaceHub(\n",
    "    repo_id = \"tiiuae/falcon-7b-instruct\",\n",
    ",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"max_length\": 64\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=model,retriever=retriever,chain_type=\"stuff\")\n",
    "response = qa(prompt)\n",
    "print(response['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
